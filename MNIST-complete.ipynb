{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](pics/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Part of the DL-CV-Workshop**: https://github.com/risc-mi/dl-cv-workshop\n",
    "\n",
    "Loosely based on https://www.kaggle.com/dejavu23/mnist-sklearn-and-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Goal**: We want to create a *deep learning model* that can correctly classify images of *hand-written digits*\n",
    "  * The model should be able to classify each of the 10 digits, based on small gray-scale images\n",
    "  * *Classifying* means returning the displayed digit as an integer between 0 and 9\n",
    "* **Examples**:<br>![digits](pics/digits.png)\n",
    "* **Challenges**:\n",
    "  * Assuming a size of $28\\times 28$ pixels and 8-bit color resolution, there are $256^{28\\cdot 28}$ different images\n",
    "  * It is difficult to design hand-crafted rules for classifying images, given the amount of variation inherent to handwritings\n",
    "    * Possibilities: average intensity, topological analysis (number of \"holes\"), etc.\n",
    "* **Methods**:\n",
    "  * We will use (a subset of) the famous [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) for training and evaluating our model\n",
    "    * Contains 42,000 gray-scale images of size $28\\times 28$ pixels\n",
    "    * Each image is *labelled* with the true digit, i.e., we know which digit is displayed $\\rightarrow$ needed for training and evaluating the model\n",
    "  * We will employ [PyTorch](https://pytorch.org/) as our deep learning framework\n",
    "    * One of the most popular deep learning frameworks\n",
    "    * Widely-used, especially in academia\n",
    "    * Prominent alternative: [TensorFlow](https://www.tensorflow.org/learn)\n",
    "  * Although digit classification is a comparatively easy problem where even simple models achieve high accuracy, we will investigate ways to further improve accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Importing the Relevant Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Evaluate code cells by hitting SHIFT+ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all plots directly in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the imported packages:\n",
    "* `numpy` is *the* Python library for efficiently working with (numerical) arrays; note that images are represented as such arrays\n",
    "* `matplotlib` is a popular plotting library for displaying images and visualizing results\n",
    "* `sklearn` (aka scikit-learn) is *the* general-purpose library for \"classical\" (non-deep-learning) ML in Python; contains lots of useful functions, some of which we are going to use here\n",
    "* `torch` is PyTorch, our deep learning framework\n",
    "  * provides `numpy`-like interface to numerical arrays called *tensors*, which in addition to actual values also record gradient information when applying operations to them\n",
    "  * gradient information can be used to automatically differentiate complicated functions and thereby solve the optimization problems encountered when training neural networks\n",
    "  * furthermore, seamlessly integrates CUDA for running computations on GPU (not used here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: PyTorch uses [Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) (AD) to compute gradients. The implementation details are intricate, but the key message is that AD is different from symbolic differentiation found in *Mathematica*, Maple, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loading and Inspecting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images and their labels are stored as Numpy arrays, which we load now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('mnist/imgs.npy')\n",
    "labels = np.load('mnist/labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape of `images` and `labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of `images` means that there are\n",
    "* 42,000 images,\n",
    "* each image has 1 color channel,\n",
    "* each image has a height of 28 pixels, and\n",
    "* each image has a width of 28 pixels.\n",
    "\n",
    "For instance, `images[i, 0, y, x]` refers to the value of pixel $(x, y)$ in the $i$-th image, for $0\\leq x,y<28$ and $0\\leq i<42000$.\n",
    "\n",
    "Likewise, the shape of `labels` means that there are 42,000 labels (one for each image, as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some images and print their labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "i = 0    # can be any number between 0 and 41999 => Python-indexing is 0-based! (negative indices count from the end)\n",
    "\n",
    "plt.imshow(images[i, 0], cmap='gray_r')     # select first (and only) color channel from `i`-th image\n",
    "plt.title('label: ' + str(labels[i]))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Colors are reversed, i.e., white has a value of 0 and black has a value of 255, contrary to usual representations. This does not really matter, though, as long as it is consistent in all experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the first 10 images of each class (i.e., digit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 10, sharex=True, sharey=True, figsize=(10, 12))\n",
    "axs = axs.flatten()\n",
    "for i in range(10):\n",
    "    for k, j in enumerate(np.flatnonzero(labels == i)[:10]):\n",
    "        axs[10 * i + k].imshow(images[j, 0], cmap='gray_r')\n",
    "        axs[10 * i + k].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of samples per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Splitting the Data into Train-, Validation- and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use one of scikit-learn's convenience functions to split the data into train-, validation- and test sets. More precisely, we set aside 25% for testing, and 20% of the remaining data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(images, labels, test_size=0.25, random_state=0)\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of training samples:', len(X_train))\n",
    "print('Number of validation samples:', len(X_val))\n",
    "print('Number of test samples:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What's the purpose of partitioning our data into these three sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: We split the data randomly. Are there situations where a completely random split is not feasible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining PyTorch Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a model in PyTorch, we have to provide our data in a particular way, via DataLoaders. This might be an overkill here, but is very useful in larger developments where images cannot be stored in memory (e.g., due to size constraints) and must be iteratively loaded, preprocessed and passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(torch.utils.data.Dataset):    # new class MNISTDataset inherits from torch.utils.data.Dataset\n",
    "\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.X[index].astype(np.float32) / 255., self.y[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(MNISTDataset(X_train, y_train), batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(MNISTDataset(X_val, y_val), batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(MNISTDataset(X_test, y_test), batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What does the `batch_size` parameter mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the first validation batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_imgs, batch_labels = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images and labels are PyTorch tensors now! They were automatically converted from the corresponding Numpy arrays by the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data type:', batch_imgs.dtype)\n",
    "print('Maximum:', batch_imgs.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type of the images changed from `uint8` to `float32`, with values in $[0, 1]$, per method `MNISTDataset.__getitem__()` defined above. Input to neural networks should be normalized or standardized, to have values around $0$ - this is beneficial for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building a Simple PyTorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's build a simple *convolutional neural network* (CNN). CNNs constitute the state-of-the-art neural network architecture for image processing (although [Vision Transformers](https://en.wikipedia.org/wiki/Vision_transformer) become increasingly popular). They consist of *convolution layers*, which apply an affine-linear transformation to all patches of a given size of their input (image). The parameters of the linear transformation (i.e., entries of the corresponding matrix) are learned by training **and are identical for every patch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![convolution](pics/convolution.gif)\n",
    "\n",
    "(Taken from https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 32, (3, 3), padding='same'),    # convolution with 1 input channel, 32 output channels, kernel size (= patch size) of 3x3\n",
    "    torch.nn.ReLU(),                                   # ReLU non-linearity, i.e., max(x, 0)\n",
    "    torch.nn.MaxPool2d(2),                             # max-pooling with kernel size of 2x2 (take maximum of all non-overlapping 2x2 patches)\n",
    "\n",
    "    torch.nn.Conv2d(32, 32, (3, 3)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "\n",
    "    torch.nn.Flatten(),                                # flatten input to shape (batch_size, 1152)\n",
    "    \n",
    "    torch.nn.Linear(1152, 256),                        # affine-linear transformation from 1152 to 256 dimensions\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.Linear(256, 10)                           # affine-linear transformation from 256 to 10 dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model` is a sequential model, i.e., the layers/operations listed above are applied sequentially. Other, more complicated architectures exist as well (and are typically employed in real-world problems)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Why does the last layer return tensors with dimension 10?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the number of parameters of each layer/operation (note that the first entry corresponds to the whole network and is the sum of the other parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    print(m.__class__.__name__ + ':', sum(p.numel() for p in m.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network architecture is visualized below. Parentheses show the shape of the output tensor of each layer (w/o batch axis).\n",
    "\n",
    "![model architecture](pics/mnist_classifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: In principle, neural networks don't need to be composed of dedicated layers, as above. Any combination of \"differentiable\" PyTorch operations is possible, although it makes sense to primarily use the dedicated layers provided by PyTorch. After all, the only requirement is that the resulting function can be (automatically) differentiated wrt. its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When constructing a neural network, its parameters are randomly initialized. Therefore, even without any training, we can apply it to input images. We cannot expect any meaningful results, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = []      # initialize empty list\n",
    "model.eval()     # set model to evaluation mode\n",
    "with torch.inference_mode():      # set PyTorch to inference mode; this avoids recording gradients, thereby increasing speed\n",
    "    for data in test_loader:      # iterate over test set, batch-wise\n",
    "        input, _ = data           # retrieve input images, ignore labels\n",
    "        y_score = model(input)    # model output with class scores for each input image, tensor of shape (128, 10)\n",
    "        y_max = torch.argmax(y_score, dim=1).numpy()     # take class with maximum score, convert to Numpy\n",
    "        y_hats.append(y_max)      # append to list\n",
    "y_hat = np.concatenate(y_hats)    # concatenate batch-wise results to single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The output returned by the model are no actual probabilities, but arbitrary scores; in particular, they can be negative and do not need to sum to $1$. However, the larger a score (relative to the others), the higher the probability of the corresponding class. Scores can be converted to probabilities by applying the [softmax function](https://en.wikipedia.org/wiki/Softmax_function), but there is no reason to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural network model amounts to solving a numerical optimization problem, which is accomplished by gradient descent. PyTorch provides several state-of-the-art numerical optimizers, including the widely-used [Adam](https://arxiv.org/abs/1412.6980):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is the meaning of the *learning rate*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need an objective function to minimize, the so-called *loss function*, which maps model predictions and true labels to scalar values. In contrast to the metrics used above, this function must be differentiable, and should be implemented in PyTorch. [Cross-entropy](https://en.wikipedia.org/wiki/Cross-entropy) is frequently used in multiclass classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define an auxiliary function for training the model for one *epoch*, i.e., one iteration over all training samples. In total, we will train the model for several epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    # iterate over all batches returned by `train_loader`\n",
    "    for data in train_loader:\n",
    "        \n",
    "        # every data instance is a pair consisting of input images and corresponding labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # set gradients to zero before every optimizer step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # apply model to input images\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # compute loss of model predictions and true labels\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # compute gradients of loss wrt. model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # perform optimization step to minimize loss, which (very roughly) amounts to updating parameters as: p_new = p_cur - learning_rate * grad\n",
    "        optimizer.step()\n",
    "\n",
    "    # return last loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are set for training the model for a specified number of epochs (which can easily be changed). In every iteration:\n",
    "* our auxiliary function `train_one_epoch` is called to train the model for one epoch,\n",
    "* the loss and accuracy of the model on the validation set are computed,\n",
    "* the training loss, validation loss and validation accuracy are saved in a `history` object, and\n",
    "* if the validation loss improved, the current parameters are saved; this allows us to load the best model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30    # adjust arbitrarily\n",
    "\n",
    "# initialize best validation loss and training history\n",
    "best_loss = np.inf\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# iterate over given number of epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}'.format(epoch + 1))\n",
    "\n",
    "    # set model to training mode (irrelevant here, but good practice in general)\n",
    "    model.train(True)\n",
    "\n",
    "    # train for one epoch\n",
    "    train_loss = train_one_epoch().item()\n",
    "\n",
    "    # compute validation loss and -accuracy\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vacc += (torch.argmax(voutputs, dim=1) == vlabels).float().mean().item()\n",
    "            running_vloss += vloss.item()\n",
    "    val_loss = running_vloss / (i + 1)\n",
    "    val_acc = running_vacc / (i + 1)\n",
    "    print('    train loss: {:.4f} | val loss: {:.4f} | val acc: {:.4f}'.format(train_loss, val_loss, val_acc))\n",
    "\n",
    "    # update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # save best parameters wrt. validation loss\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'mnist/model_best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load the training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(history, open('mnist/training_history_augmentation.pkl', mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#history = pickle.load(open('mnist/training_history_pretrained.pkl', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plot the training history, in particular the validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['val_acc'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy should not be used to assess the predictive quality of a model. Instead, the model should be evaluated on a completely independent test set.\n",
    "\n",
    "**Question**: Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the best parameters, i.e., the parameters where the validation loss during training was minimal. Alternatively, you can also try `\"mnist/model_pretrained.pt\"`, with pre-trained parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('mnist/model_best.pt'))     # either \"model_pretrained.pt\" or \"model_best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above\n",
    "y_hats = []\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for data in test_loader:\n",
    "        input, _ = data\n",
    "        y_score = model(input)\n",
    "        y_max = torch.argmax(y_score, dim=1).numpy()\n",
    "        y_hats.append(y_max)\n",
    "y_hat = np.concatenate(y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In addition to simple scalar values, we can also evaluate predictive performance more comprehensively, e.g., through a *confusion matrix*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "plt.imshow(matrix)\n",
    "for i in range(len(matrix)):\n",
    "    for j in range(len(matrix)):\n",
    "        text = plt.gca().text(j, i, matrix[i, j], ha='center', va='center', color='w')\n",
    "plt.xticks(np.arange(len(matrix)))\n",
    "plt.yticks(np.arange(len(matrix)))\n",
    "plt.xlabel('predicted class')\n",
    "plt.ylabel('true class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What does the confusion matrix tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the indices of all wrongly classified samples in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx = np.flatnonzero(y_hat != y_test)    # `np.flatnonzero()` returns the indices of all True elements in a boolean array\n",
    "len(wrong_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect wrong predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7, 7, sharex=True, sharey=True, figsize=(10, 12))\n",
    "axs = axs.flatten()\n",
    "for i, j in zip(range(len(axs)), wrong_idx):\n",
    "    axs[i].imshow(X_test[j, 0], cmap='gray_r')\n",
    "    axs[i].set_title('true: {}\\npredicted: {}'.format(y_test[j], y_hat[j]))\n",
    "    axs[i].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Classification of Handwritten Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play around and have the model classify our own handwriting! This little app is implemented in a separate Python file, which we simply import now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the following command and draw digits (or whatever you like) in the white box. Right-click to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for interactive Matplotlib figures\n",
    "%matplotlib widget\n",
    "\n",
    "canvas = mnist.canvas(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close interactive plot to release resources\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What happens if you draw other symbols, like letters? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What can we do to further increase classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Obvious\" Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the model for more epochs. However, be aware that the model may start to [overfit](https://en.wikipedia.org/wiki/Overfitting) at some point, i.e., the training loss keeps decreasing, but the validation loss starts to increase. **In other words, the model learns the training set by heart and fails to generalize to unseen data.**\n",
    "* Collect more training data. The more data, the better, but be aware that the data used for training the model should as closely as possible match the data the model will be applied to afterward. **In other words, training- and test data should be drawn from the same distribution.**\n",
    "* Change the network architecture, possibly increasing the number of trainable parameters and/or adding regularization. More parameters lead to more expressive models that tend to overfit sooner, whereas regularization (e.g., [batch normalization](https://en.wikipedia.org/wiki/Batch_normalization), [dropout](https://en.wikipedia.org/wiki/Dilution_(neural_networks)), [weight decay](https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab)) helps to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ensembling* means training several independent models, applying all of them to a given input, and combining their individual outputs to obtain the final prediction. This leads to an improvement of predictive performance in many cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual models can be trained in many different ways, including:\n",
    "* training the same neural network architecture on the same data, relying on randomness inherent to the training process (e.g., parameter initialization, order of training samples, stochastic network layers [e.g., Dropout]),\n",
    "* training each model on a different subset of the training data,\n",
    "* using different optimizers,\n",
    "* using different neural network architectures,\n",
    "* using completely different ML algorithms, like neural networks, random forests, support vector machines, etc.\n",
    "\n",
    "Likewise, the individual outputs can be combined in several ways, including:\n",
    "* averaging scores or probabilities and returning the most probable class after averaging,\n",
    "* returning the class predicted by most models (\"voting\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a straightforward technique to improve predictive performance. You can easily try it yourself.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is one of the most widely used techniques to improve image classification models. It is based on the following key idea: **Slightly modifying an image, e.g., by rotating, resizing, cropping, etc., does not change the class label.** So, by modifying our training images, we can **massively increase** the size of our training set **for free.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will restrict ourselves to rotations, but you can easily try out other augmentation techniques yourself. For instance, the [imgaug](https://imgaug.readthedocs.io/en/latest/) and [torchvision](https://pytorch.org/vision/stable/transforms.html) Python packages implement lots of ready-to-use augmentations and can easily be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a function to rotate images by arbitrary angles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "img_idx = 10   # index of image to rotate, within `images`\n",
    "\n",
    "fig, axs = plt.subplots(1, 11, sharex=True, sharey=True, figsize=(11, 3))\n",
    "axs = axs.flatten()\n",
    "for i, angle in enumerate([-25, -20, -15, -10, -5, 0, 5, 10, 15, 20, 25]):\n",
    "    img = rotate(images[img_idx], angle, axes=(1, 2), reshape=False)     # axes=(1, 2), because axes 1 and 2 correspond to spatial dimensions\n",
    "    axs[i].imshow(img[0], cmap='gray_r')\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('{}Â°'.format(angle))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to incorporate augmentation into our model-training workflow is via the `MNISTDataset` class defined above. We simply need to redefine the `__getitem__` method of that class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTAugmentedDataset(MNISTDataset):\n",
    "\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, max_angle: float = 25.):\n",
    "        super(MNISTAugmentedDataset, self).__init__(X, y)\n",
    "        self.max_angle = max_angle\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        img, lbl = super(MNISTAugmentedDataset, self).__getitem__(index)\n",
    "\n",
    "        # img is a float-array of shape (1, 28, 28), with values in [0, 1] interval, and lbl is its class label\n",
    "\n",
    "        # only rotate if max_angle is positive => allows to disable augmentation\n",
    "        if self.max_angle > 0:\n",
    "            # choose random number, uniformly distributed between -max_angle and max_angle\n",
    "            # note: we could seed the random number generator to obtain reproducible results\n",
    "            angle = np.random.uniform(-self.max_angle, self.max_angle)\n",
    "            \n",
    "            img = rotate(img, angle, axes=(1, 2), reshape=False)\n",
    "            np.clip(img, 0, 1, out=img)    # clip to [0, 1] interval\n",
    "\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the `train_loader`. We do not want to augment validation- and test images here, so there is no need to update `val_loader` and `test_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(MNISTAugmentedDataset(X_train, y_train, max_angle=25), batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest proceeds as above, literally without changes. Only note that since the training data changes in every epoch due to data augmentation, we should be able to train for more epochs without overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Would it make sense to augment the validation- and test images as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We followed these **general steps** to obtain an accurate image classification model:\n",
    "1. Collect a sufficient amount of *labeled* data.\n",
    "   * \"Sufficient\" depends a lot on the data modality, number of classes and problem difficulty.\n",
    "   * Labels are important; however, there exist strategies for training models without explicitly provided labels, too, so-called *self-supervised learning*.\n",
    "2. Thoroughly analyze data to identify potential biases.\n",
    "   * Okay, we didn't analyze our data very thoroughly, because MNIST is a well-established dataset.\n",
    "   * If we had collected the data ourselves, this step would be extremely important, though! Bias can be **everywhere** and is easily overlooked.\n",
    "3. Define non-overlapping training, validation and test sets.\n",
    "   * Final predictive performance should only be assessed on the test set, which must not be used for model training at all.\n",
    "   * If only few data are available, more data-efficient splitting strategies exist as well, e.g., $k$-fold cross validation.\n",
    "4. Define a suitable neural network architecture.\n",
    "   * \"Suitable\" depends a lot on the specific use-case.\n",
    "   * Convolutional neural networks, and recently Vision Transformers, still represent the state-of-the-art in computer vision.\n",
    "5. Train the model on the training set.\n",
    "   * Use the validation set to monitor the training progress and detect overfitting.\n",
    "   * Consider employing data augmentation to artificially increase the training set.\n",
    "6. Thoroughly evaluate the final model on the test set.\n",
    "   * Calculate different performance metrics and investigate failure cases.\n",
    "7. Go back to step 1 if model performance is not sufficient.\n",
    "   * Also, consider techniques such as ensembling to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:-cv_dl_tutorial]",
   "language": "python",
   "name": "conda-env--cv_dl_tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
